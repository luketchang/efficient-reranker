{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from enum import Enum\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    QUERY = 0,\n",
    "    DOC = 1\n",
    "\n",
    "class EncoderDataset(Dataset):\n",
    "    def __init__(self, dataset_type: DatasetType, input_path, tokenizer, max_seq_len=None, max_lines=None, prefix_examples=None, qrels_filter_path=None):\n",
    "        self.dataset_type = dataset_type\n",
    "        self.input_path = input_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_lines = max_lines\n",
    "        self.task = 'Given a query, retrieve relevant passages that answer the query.'\n",
    "        self.data = []\n",
    "        self.qrels_filter_path = qrels_filter_path\n",
    "\n",
    "        self._load_examples_prefix(prefix_examples)\n",
    "        self._load_data(qrels_filter_path)\n",
    "\n",
    "    def _load_qrels(self, qrels_filter_path):\n",
    "        qids = set()\n",
    "        with open(qrels_filter_path, 'r') as file:\n",
    "            for line in file:\n",
    "                qid = line.strip().split()[0]  # Assuming QREL format where QID is the first column\n",
    "                qids.add(qid)\n",
    "        return qids\n",
    "\n",
    "    def _load_data(self, qrels_filter_path=None):\n",
    "        # Load QIDs filter from qrels if provided\n",
    "        qids_filter = set()\n",
    "        if self.dataset_type == DatasetType.QUERY and self.qrels_filter_path:\n",
    "            qids_filter = self._load_qrels(qrels_filter_path)\n",
    "            print(f\"Loaded {len(qids_filter)} qids from qrels filter.\")\n",
    "\n",
    "        # Load the data\n",
    "        with open(self.input_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if self.max_lines and i >= self.max_lines:\n",
    "                    break\n",
    "                data = json.loads(line)\n",
    "                id = data[\"_id\"].replace(\"doc\", \"\").replace(\"test\", \"\")  # Remove prefixes\n",
    "                \n",
    "                # Filter queries if QIDs filter is applied\n",
    "                if self.dataset_type == DatasetType.QUERY and qids_filter and id not in qids_filter:\n",
    "                    continue\n",
    "\n",
    "                title = data.get(\"title\", \"\")\n",
    "                text = data[\"text\"]\n",
    "                passage = title + \" \" + text if title else text\n",
    "                self.data.append({\"id\": int(id), \"text\": passage})\n",
    "\n",
    "    def _load_examples_prefix(self, examples):\n",
    "        if examples is None:\n",
    "            examples = [\n",
    "                {'instruct': self.task,\n",
    "                'query': 'what is a virtual interface',\n",
    "                'response': \"A virtual interface is a software-defined abstraction that mimics the behavior and characteristics of a physical network interface. It allows multiple logical network connections to share the same physical network interface, enabling efficient utilization of network resources. Virtual interfaces are commonly used in virtualization technologies such as virtual machines and containers to provide network connectivity without requiring dedicated hardware. They facilitate flexible network configurations and help in isolating network traffic for security and management purposes.\"},\n",
    "                {'instruct': self.task,\n",
    "                'query': 'causes of back pain in female for a week',\n",
    "                'response': \"Back pain in females lasting a week can stem from various factors. Common causes include muscle strain due to lifting heavy objects or improper posture, spinal issues like herniated discs or osteoporosis, menstrual cramps causing referred pain, urinary tract infections, or pelvic inflammatory disease. Pregnancy-related changes can also contribute. Stress and lack of physical activity may exacerbate symptoms. Proper diagnosis by a healthcare professional is crucial for effective treatment and management.\"}\n",
    "                ]            \n",
    "        examples = [self.get_detailed_example(e['instruct'], e['query'], e['response']) for e in examples]\n",
    "        self.examples_prefix = '\\n\\n'.join(examples) + '\\n\\n' \n",
    "\n",
    "    def get_detailed_example(self, task_description: str, query: str, response: str) -> str:\n",
    "        return f'<instruct>{task_description}\\n<query>{query}\\n<response>{response}'\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the size of the dataset.\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns a tokenized sample.\"\"\"\n",
    "        sample = self.data[idx]\n",
    "        text = sample[\"text\"]\n",
    "        id = sample[\"id\"]\n",
    "\n",
    "        return {\n",
    "            \"id\": id,\n",
    "            \"text\": text\n",
    "        }\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        # Extract the elements in the batch\n",
    "        ids = [sample['id'] for sample in batch]\n",
    "        texts = [sample['text'] for sample in batch]\n",
    "\n",
    "        max_len = self.max_seq_len\n",
    "        if self.dataset_type == DatasetType.QUERY:\n",
    "            max_len, texts = self.get_new_queries(texts)\n",
    "            \n",
    "        tokenized = self.tokenizer(\n",
    "            texts,\n",
    "            max_length=max_len,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),  # Convert ids to tensor\n",
    "            \"input_ids\": tokenized[\"input_ids\"],\n",
    "            \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        }\n",
    "\n",
    "    def get_new_queries(self, queries):\n",
    "        inputs = self.tokenizer(\n",
    "            queries,\n",
    "            max_length=self.max_seq_len - len(self.tokenizer('<s>', add_special_tokens=False)['input_ids']) - len(\n",
    "                self.tokenizer('\\n<response></s>', add_special_tokens=False)['input_ids']),\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True,\n",
    "            return_tensors=None,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "        prefix_ids = self.tokenizer(self.examples_prefix, add_special_tokens=False)['input_ids']\n",
    "        suffix_ids = self.tokenizer('\\n<response>', add_special_tokens=False)['input_ids']\n",
    "        new_max_length = (len(prefix_ids) + len(suffix_ids) + self.max_seq_len + 8) // 8 * 8 + 8\n",
    "        new_queries = self.tokenizer.batch_decode(inputs['input_ids'])\n",
    "        for i in range(len(new_queries)):\n",
    "            new_queries[i] = self.examples_prefix + new_queries[i] + '\\n<response>'\n",
    "        return new_max_length, new_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-en-icl')\n",
    "dataset = EncoderDataset(DatasetType.QUERY, '../data/nq/queries.jsonl', tokenizer, max_seq_len=512, max_lines=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': tensor([500, 720]), 'input_ids': tensor([[    0,     1, 32000, 12628,   264,  5709, 28725, 20132,  8598,  1455,\n",
      "          1291,   369,  4372,   272,  5709, 28723,    13, 32001,   767,   349,\n",
      "           264,  8252,  4971,    13, 32002,   330,  8252,  4971,   349,   264,\n",
      "          3930, 28733, 11498,   534,  6781,   445,   369, 26302,  1063,   272,\n",
      "          6174,   304, 15559,   302,   264,  5277,  3681,  4971, 28723,   661,\n",
      "          5976,  5166, 16441,  3681, 12284,   298,  4098,   272,  1348,  5277,\n",
      "          3681,  4971, 28725, 25748,  9096,  4479,  1837,   302,  3681,  5823,\n",
      "         28723, 19032,   791,  9288,   460, 14473,  1307,   297,  8252,  1837,\n",
      "         14880,  1259,   390,  8252, 12155,   304, 25399,   298,  3084,  3681,\n",
      "          5789,  2574,  1671, 22579, 10383, 13218, 28723,  1306, 25729, 17574,\n",
      "          3681, 24991,   304,  1316,   297,  9777,  1077,  3681,  8475,   354,\n",
      "          4908,   304,  5411, 10700, 28723,    13,    13, 32000, 12628,   264,\n",
      "          5709, 28725, 20132,  8598,  1455,  1291,   369,  4372,   272,  5709,\n",
      "         28723,    13, 32001, 10110,   302,   852,  3358,   297,  7742,   354,\n",
      "           264,  1819,    13, 32002,  6795,  3358,   297, 21903, 24266,   264,\n",
      "          1819,   541, 17854,   477,  4118,  8612, 28723, 10757, 10110,  3024,\n",
      "         14540, 20842,  2940,   298, 22853,  5917,  6697,   442,  3267,   487,\n",
      "          1704,   482, 28725,   668,  1475,  4382,   737,   559,  3023,   601,\n",
      "          2312, 28713,   442,   289,  2453,   410,   271,  9795, 28725,  1683,\n",
      "         14664,   282,  1439, 10991, 13098, 11449,  3358, 28725,  4273,  3239,\n",
      "         25180,   297, 23498, 28725,   442,  6704, 28728,   294,  3661,   314,\n",
      "          3076,   695,  8030, 28723,   367,  1376, 28711,  5403, 28733,  9646,\n",
      "          4435,   541,   835, 14951, 28723,   662,   638,   304,  5502,   302,\n",
      "          5277,  6355,   993,   439,  9172, 28726,   380, 12380, 28723,  1133,\n",
      "           487, 21967,   486,   264, 15240,  5024,   349, 13040,   354,  5645,\n",
      "          5827,   304,  5411, 28723,    13,    13,  2956,   863,  3229,   272,\n",
      "          5114,   509,  2791,  1388,  1633,    13, 32002,     2],\n",
      "        [    1, 32000, 12628,   264,  5709, 28725, 20132,  8598,  1455,  1291,\n",
      "           369,  4372,   272,  5709, 28723,    13, 32001,   767,   349,   264,\n",
      "          8252,  4971,    13, 32002,   330,  8252,  4971,   349,   264,  3930,\n",
      "         28733, 11498,   534,  6781,   445,   369, 26302,  1063,   272,  6174,\n",
      "           304, 15559,   302,   264,  5277,  3681,  4971, 28723,   661,  5976,\n",
      "          5166, 16441,  3681, 12284,   298,  4098,   272,  1348,  5277,  3681,\n",
      "          4971, 28725, 25748,  9096,  4479,  1837,   302,  3681,  5823, 28723,\n",
      "         19032,   791,  9288,   460, 14473,  1307,   297,  8252,  1837, 14880,\n",
      "          1259,   390,  8252, 12155,   304, 25399,   298,  3084,  3681,  5789,\n",
      "          2574,  1671, 22579, 10383, 13218, 28723,  1306, 25729, 17574,  3681,\n",
      "         24991,   304,  1316,   297,  9777,  1077,  3681,  8475,   354,  4908,\n",
      "           304,  5411, 10700, 28723,    13,    13, 32000, 12628,   264,  5709,\n",
      "         28725, 20132,  8598,  1455,  1291,   369,  4372,   272,  5709, 28723,\n",
      "            13, 32001, 10110,   302,   852,  3358,   297,  7742,   354,   264,\n",
      "          1819,    13, 32002,  6795,  3358,   297, 21903, 24266,   264,  1819,\n",
      "           541, 17854,   477,  4118,  8612, 28723, 10757, 10110,  3024, 14540,\n",
      "         20842,  2940,   298, 22853,  5917,  6697,   442,  3267,   487,  1704,\n",
      "           482, 28725,   668,  1475,  4382,   737,   559,  3023,   601,  2312,\n",
      "         28713,   442,   289,  2453,   410,   271,  9795, 28725,  1683, 14664,\n",
      "           282,  1439, 10991, 13098, 11449,  3358, 28725,  4273,  3239, 25180,\n",
      "           297, 23498, 28725,   442,  6704, 28728,   294,  3661,   314,  3076,\n",
      "           695,  8030, 28723,   367,  1376, 28711,  5403, 28733,  9646,  4435,\n",
      "           541,   835, 14951, 28723,   662,   638,   304,  5502,   302,  5277,\n",
      "          6355,   993,   439,  9172, 28726,   380, 12380, 28723,  1133,   487,\n",
      "         21967,   486,   264, 15240,  5024,   349, 13040,   354,  5645,  5827,\n",
      "           304,  5411, 28723,    13,    13,  2956,   403,   272,   907,   261,\n",
      "         28750, 28734, 26023,  2918,  4226,    13, 32002,     2]]), 'attention_mask': tensor([[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk><s><instruct> Given a query, retrieve relevant passages that answer the query.\\n<query> what is a virtual interface\\n<response> A virtual interface is a software-defined abstraction that mimics the behavior and characteristics of a physical network interface. It allows multiple logical network connections to share the same physical network interface, enabling efficient utilization of network resources. Virtual interfaces are commonly used in virtualization technologies such as virtual machines and containers to provide network connectivity without requiring dedicated hardware. They facilitate flexible network configurations and help in isolating network traffic for security and management purposes.\\n\\n<instruct> Given a query, retrieve relevant passages that answer the query.\\n<query> causes of back pain in female for a week\\n<response> Back pain in females lasting a week can stem from various factors. Common causes include muscle strain due to lifting heavy objects or improper posture, spinal issues like herniated discs or osteoporosis, menstrual cramps causing referred pain, urinary tract infections, or pelvic inflammatory disease. Pregnancy-related changes can also contribute. Stress and lack of physical activity may exacerbate symptoms. Proper diagnosis by a healthcare professional is crucial for effective treatment and management.\\n\\nwhere did remember the titans camp take place\\n<response></s>',\n",
       " '<s><instruct> Given a query, retrieve relevant passages that answer the query.\\n<query> what is a virtual interface\\n<response> A virtual interface is a software-defined abstraction that mimics the behavior and characteristics of a physical network interface. It allows multiple logical network connections to share the same physical network interface, enabling efficient utilization of network resources. Virtual interfaces are commonly used in virtualization technologies such as virtual machines and containers to provide network connectivity without requiring dedicated hardware. They facilitate flexible network configurations and help in isolating network traffic for security and management purposes.\\n\\n<instruct> Given a query, retrieve relevant passages that answer the query.\\n<query> causes of back pain in female for a week\\n<response> Back pain in females lasting a week can stem from various factors. Common causes include muscle strain due to lifting heavy objects or improper posture, spinal issues like herniated discs or osteoporosis, menstrual cramps causing referred pain, urinary tract infections, or pelvic inflammatory disease. Pregnancy-related changes can also contribute. Stress and lack of physical activity may exacerbate symptoms. Proper diagnosis by a healthcare professional is crucial for effective treatment and management.\\n\\nwhere was the first t20 cricket match played\\n<response></s>']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    QUERY = 0,\n",
    "    DOC = 1\n",
    "\n",
    "def load_qrels(qrels_path):\n",
    "        qids = set()\n",
    "        with open(qrels_path, 'r') as file:\n",
    "            for line in file:\n",
    "                qid = line.strip().split()[0]\n",
    "                qid = qid.replace(\"query\", \"\").replace(\"test\", \"\").replace(\"train\", \"\").replace(\"dev\", \"\")\n",
    "                qids.add(qid)\n",
    "        return qids\n",
    "\n",
    "def load_data_from_jsonl(dataset_type, input_path, qrels_filter_path=None, start_line=0, max_lines=None):\n",
    "        data_arr = []\n",
    "        qids_filter = set()\n",
    "        if dataset_type == DatasetType.QUERY and qrels_filter_path:\n",
    "            qids_filter = load_qrels(qrels_filter_path)\n",
    "            print(f\"Loaded {len(qids_filter)} qids from qrels filter.\")\n",
    "\n",
    "        # Load the data\n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                # continue until start line reached\n",
    "                if i < start_line:\n",
    "                    continue\n",
    "\n",
    "                # break if max lines reached\n",
    "                if max_lines and i - start_line >= max_lines:\n",
    "                    break\n",
    "\n",
    "                data = json.loads(line)\n",
    "                id = data[\"_id\"].replace(\"doc\", \"\").replace(\"test\", \"\").replace(\"train\", \"\").replace(\"dev\", \"\")\n",
    "                \n",
    "                # Filter queries if QIDs filter is applied\n",
    "                if dataset_type == DatasetType.QUERY and qids_filter and id not in qids_filter:\n",
    "                    print(\"Skipping query\", id)\n",
    "                    continue\n",
    "\n",
    "                title = data.get(\"title\", \"\")\n",
    "                text = data[\"text\"]\n",
    "                passage = title + \"\\n\" + text if title and title != \"\" else text\n",
    "                data_arr.append({\"id\": int(id), \"text\": passage})\n",
    "\n",
    "        return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RawTextDataset(Dataset):\n",
    "    def __init__(self, dataset_type: DatasetType, input_path, start_line=0, max_lines=None, qrels_filter_path=None):\n",
    "        self.dataset_type = dataset_type\n",
    "        self.input_path = input_path\n",
    "        self.max_lines = max_lines\n",
    "        self.qrels_filter_path = qrels_filter_path\n",
    "\n",
    "        # Load data from the input JSONL file\n",
    "        self.data = load_data_from_jsonl(dataset_type, input_path, qrels_filter_path, start_line, max_lines)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        return {\n",
    "            \"id\": sample[\"id\"],\n",
    "            \"text\": sample[\"text\"]\n",
    "        }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        ids = [sample['id'] for sample in batch]\n",
    "        texts = [sample['text'] for sample in batch]\n",
    "\n",
    "        if self.dataset_type == DatasetType.QUERY:\n",
    "            texts = [f'Instruct: Retrieve relevant passages.\\nQuery: {text}' for text in texts]\n",
    "\n",
    "        return {\n",
    "            \"ids\": ids,\n",
    "            \"text\": texts  # Just return raw text strings\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RawTextDataset(DatasetType.DOC, '../data/nq/corpus.jsonl', max_lines=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [924, 879], 'text': ['Geography of Spain\\nSpain also has a small exclave inside France called Llívia.', 'Comanche\\nThe Comanche sheathed their tipis with a covering made of buffalo hides sewn together. To prepare the buffalo hides, women first spread them on the ground, then scraped away the fat and flesh with blades made from bones or antlers, and left them in the sun. When the hides were dry, they scraped off the thick hair, and then soaked them in water. After several days, they vigorously rubbed the hides in a mixture of animal fat, brains, and liver to soften the hides. The hides were made even more supple by further rinsing and working back and forth over a rawhide thong. Finally, they were smoked over a fire, which gave the hides a light tan color. To finish the tipi covering, women laid the tanned hides side by side and stitched them together. As many as 22 hides could be used, but 14 was the average. When finished, the hide covering was tied to a pole and raised, wrapped around the cone-shaped frame, and pinned together with pencil-sized wooden skewers. Two wing-shaped flaps at the top of the tipi were turned back to make an opening, which could be adjusted to keep out the moisture and held pockets of insulating air. With a fire pit in the center of the earthen floor, the tipis stayed warm in the winter. In the summer, the bottom edges of the tipis could be rolled up to let cool breezes in. Cooking was done outside during the hot weather. Tipis were very practical homes for itinerant people. Working together, women could quickly set them up or take them down. An entire Comanche band could be packed and chasing a buffalo herd within about 20 minutes. The Comanche women were the ones who did the most work with food processing and preparation.[74]']}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comanche\\nThe Comanche sheathed their tipis with a covering made of buffalo hides sewn together. To prepare the buffalo hides, women first spread them on the ground, then scraped away the fat and flesh with blades made from bones or antlers, and left them in the sun. When the hides were dry, they scraped off the thick hair, and then soaked them in water. After several days, they vigorously rubbed the hides in a mixture of animal fat, brains, and liver to soften the hides. The hides were made even more supple by further rinsing and working back and forth over a rawhide thong. Finally, they were smoked over a fire, which gave the hides a light tan color. To finish the tipi covering, women laid the tanned hides side by side and stitched them together. As many as 22 hides could be used, but 14 was the average. When finished, the hide covering was tied to a pole and raised, wrapped around the cone-shaped frame, and pinned together with pencil-sized wooden skewers. Two wing-shaped flaps at the top of the tipi were turned back to make an opening, which could be adjusted to keep out the moisture and held pockets of insulating air. With a fire pit in the center of the earthen floor, the tipis stayed warm in the winter. In the summer, the bottom edges of the tipis could be rolled up to let cool breezes in. Cooking was done outside during the hot weather. Tipis were very practical homes for itinerant people. Working together, women could quickly set them up or take them down. An entire Comanche band could be packed and chasing a buffalo herd within about 20 minutes. The Comanche women were the ones who did the most work with food processing and preparation.[74]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
