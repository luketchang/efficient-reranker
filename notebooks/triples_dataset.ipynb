{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_hits_from_qrels_queries_corpus(qrels_file, queries_file, corpus_file=None):\n",
    "    print(f\"Loading qids from '{queries_file}'\")\n",
    "    queries = load_qids_to_queries(queries_file)\n",
    "\n",
    "    print(f\"Loading corpus from '{corpus_file}'\")\n",
    "    corpus = load_pids_to_passages(corpus_file) if corpus_file is not None else None\n",
    "\n",
    "    # Step 3: Load qrels and combine all data\n",
    "    results = {}\n",
    "    with open(qrels_file, 'r') as f:\n",
    "        for line in f:\n",
    "            # Skip if the first line is the header\n",
    "            if line.startswith(\"query-id\"):\n",
    "                continue\n",
    "\n",
    "            qid, docid, score = line.strip().split('\\t')\n",
    "            score = float(score)\n",
    "\n",
    "            # Initialize query entry if not already present\n",
    "            if qid not in results:\n",
    "                results[qid] = {'query': queries[qid], 'hits': []}\n",
    "\n",
    "            # Create a hit entry\n",
    "            hit = {\n",
    "                'qid': qid,\n",
    "                'docid': docid,\n",
    "                'score': score,\n",
    "                'content': corpus[docid] if corpus_file is not None else None\n",
    "            }\n",
    "\n",
    "            results[qid]['hits'].append(hit)\n",
    "\n",
    "    # Step 4: Sort the queries by numeric qid and their hits by score\n",
    "    rank_results = []\n",
    "    for qid in sorted(results.keys(), key=lambda x: int(x.replace(\"test\", \"\").replace(\"train\", \"\").replace(\"dev\", \"\"))):  # Sort by numeric qid\n",
    "        sorted_hits = sorted(\n",
    "            results[qid]['hits'], \n",
    "            key=lambda x: -x['score']  # Sort hits by score in descending order\n",
    "        )\n",
    "        rank_results.append({\n",
    "            'query': results[qid]['query'],\n",
    "            'hits': sorted_hits\n",
    "        })\n",
    "\n",
    "    return rank_results\n",
    "\n",
    "def load_qids_to_queries(queries_file):\n",
    "    queries = {}\n",
    "    with open(queries_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line)\n",
    "            qid, query = line[\"_id\"], line[\"text\"]\n",
    "            queries[qid] = query\n",
    "    return queries\n",
    "\n",
    "def load_pids_to_passages(corpus_file):\n",
    "    corpus = {}\n",
    "    with open(corpus_file, 'r') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            pid = data[\"_id\"]\n",
    "            \n",
    "            # Extract title and text, combining them if the title exists\n",
    "            title = data.get(\"title\", \"\")\n",
    "            text = data[\"text\"]\n",
    "            passage = title + \"\\n\" + text if title and title.strip() else text\n",
    "            \n",
    "            corpus[pid] = passage\n",
    "    return corpus\n",
    "\n",
    "def load_qid_to_pid_to_score(qrels_file):\n",
    "    qid_to_pid_to_score = {}\n",
    "    with open(qrels_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"query-id\"):\n",
    "                continue\n",
    "\n",
    "            qid, pid, score = line.strip().split('\\t')\n",
    "            score = float(score)\n",
    "            \n",
    "            if qid not in qid_to_pid_to_score:\n",
    "                qid_to_pid_to_score[qid] = {}\n",
    "            qid_to_pid_to_score[qid][pid] = score\n",
    "    return qid_to_pid_to_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "# from data_utils import load_qid_to_pid_to_score, load_pids_to_passages, load_hits_from_qrels_queries_corpus, strip_prefixes\n",
    "import random\n",
    "\n",
    "class PositiveNegativeDataset(Dataset):\n",
    "    def __init__(self, queries_path, corpus_path, negative_rank_results_path, positive_rank_results_path, tokenizer, max_seq_len=None, num_neg_per_pos=8, seed=43):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.positive_rank_results = load_qid_to_pid_to_score(positive_rank_results_path)\n",
    "        self.corpus = load_pids_to_passages(corpus_path)\n",
    "        negative_rank_results = load_hits_from_qrels_queries_corpus(negative_rank_results_path, queries_path, corpus_path)\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.truncation = max_seq_len is not None\n",
    "        self.num_neg_per_pos = num_neg_per_pos  # Number of negatives to sample\n",
    "        self.seed = seed  # Global seed\n",
    "\n",
    "        self.negative_rank_results_with_positives = []\n",
    "        for rank_result in negative_rank_results:\n",
    "            hits = rank_result['hits']\n",
    "            qid = hits[0]['qid']\n",
    "            if qid in self.positive_rank_results:\n",
    "                for positive_id in self.positive_rank_results[qid]:\n",
    "                    positive_score = self.positive_rank_results[qid][positive_id]\n",
    "                    self.negative_rank_results_with_positives.append({\n",
    "                        \"query_id\": qid,\n",
    "                        \"query\": rank_result['query'],\n",
    "                        \"positive_id\": positive_id,\n",
    "                        \"positive_score\": positive_score,\n",
    "                        \"hits\": hits  # All hits for negative sampling\n",
    "                    })\n",
    "\n",
    "        # Create index mapping: [(query_idx, hit_idx)]\n",
    "        self.index_mapping = []\n",
    "        for query_idx, rank_result in enumerate(self.negative_rank_results_with_positives):\n",
    "            num_hits = len(rank_result['hits'])\n",
    "            self.index_mapping.extend([query_idx for _ in range(num_hits // self.num_neg_per_pos)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_mapping)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        query_idx = self.index_mapping[idx]\n",
    "        rank_result = self.negative_rank_results_with_positives[query_idx]\n",
    "        query = rank_result['query']\n",
    "\n",
    "        # Positive passage\n",
    "        positive_id = rank_result['positive_id']\n",
    "        positive_passage = self.corpus[positive_id]\n",
    "\n",
    "        # Use local RNG for sampling negatives conditioned on seed + idx\n",
    "        local_rng = random.Random(self.seed + idx)\n",
    "\n",
    "        # Sample negatives deterministically but locally, using local_rng\n",
    "        negative_candidates = [hit for hit in rank_result['hits'] if hit['docid'] != positive_id]\n",
    "        hard_negatives = local_rng.sample(negative_candidates, self.num_neg_per_pos)\n",
    "\n",
    "        return {\n",
    "            \"query_id\": rank_result['query_id'],\n",
    "            \"query\": query,\n",
    "            \"positive_id\": positive_id,\n",
    "            \"positive\": positive_passage,\n",
    "            \"positive_label\": rank_result['positive_score'],\n",
    "            \"negative_ids\": [neg['docid'] for neg in hard_negatives],\n",
    "            \"negatives\": [self.corpus[neg['docid']] for neg in hard_negatives],\n",
    "            \"negative_labels\": [neg['score'] for neg in hard_negatives]\n",
    "        }\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        queries = [item['query'] for item in batch]\n",
    "        positive_passages = [item['positive'] for item in batch]\n",
    "        positive_labels = [item['positive_label'] for item in batch]\n",
    "        negatives_flattened = [neg for item in batch for neg in item['negatives']]\n",
    "        negative_labels_flattened = [label for item in batch for label in item['negative_labels']]\n",
    "        \n",
    "        # Tokenize positives and negatives\n",
    "        tokenized_positives = self.tokenizer(queries, positive_passages, padding=True, truncation=self.truncation, return_tensors=\"pt\", max_length=self.max_seq_len)\n",
    "        repeated_queries = [query for query in queries for _ in range(self.num_neg_per_pos)]\n",
    "        tokenized_negatives = self.tokenizer(repeated_queries, negatives_flattened, padding=True, truncation=self.truncation, return_tensors=\"pt\", max_length=self.max_seq_len)\n",
    "        \n",
    "        return {\n",
    "            \"positives\": tokenized_positives,\n",
    "            \"positive_labels\": torch.tensor(positive_labels),\n",
    "            \"negatives\": tokenized_negatives,\n",
    "            \"negative_labels\": torch.tensor(negative_labels_flattened)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading qids from '../data/nq-train/queries_sampled_10000.jsonl'\n",
      "Loading corpus from '../data/nq/corpus.jsonl'\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "queries_path = \"../data/nq-train/queries_sampled_10000.jsonl\"\n",
    "corpus_path = \"../data/nq/corpus.jsonl\"\n",
    "negative_rank_results_path = \"../data/nq-train/nv_rerank_negatives_top200_sampled_10000_filtered.tsv\"\n",
    "positive_rank_results_path = \"../data/nq-train/nv_rerank_positives_train_sampled_10000.tsv\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")\n",
    "dataset = PositiveNegativeDataset(queries_path, corpus_path, negative_rank_results_path, positive_rank_results_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230341"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': 'train128298',\n",
       " 'query': 'when did the 16th amendment to the constitution legalize the levying of income tax by congress',\n",
       " 'positive_id': 'doc330670',\n",
       " 'positive': \"Sixteenth Amendment to the United States Constitution\\nThe Sixteenth Amendment (Amendment XVI) to the United States Constitution allows the Congress to levy an income tax without apportioning it among the states or basing it on the United States Census. This amendment exempted income taxes from the constitutional requirements regarding direct taxes, after income taxes on rents, dividends, and interest were ruled to be direct taxes in the court case of Pollock v. Farmers' Loan & Trust Co. (1895). The amendment was adopted on February 3, 1913.\",\n",
       " 'positive_label': 38.0625,\n",
       " 'negative_ids': ['doc1056930',\n",
       "  'doc1919320',\n",
       "  'doc330680',\n",
       "  'doc1506229',\n",
       "  'doc1497051',\n",
       "  'doc648899',\n",
       "  'doc330731',\n",
       "  'doc440422'],\n",
       " 'negatives': [\"History of taxation in the United States\\nIn 1895, the United States Supreme Court ruled, in Pollock v. Farmers' Loan & Trust Co., that taxes on rents from real estate, on interest income from personal property and other income from personal property (which includes dividend income) were direct taxes on property and therefore had to be apportioned. Since apportionment of income taxes is impractical, the Pollock rulings had the effect of prohibiting a federal tax on income from property. Due to the political difficulties of taxing individual wages without taxing income from property, a federal income tax was impractical from the time of the Pollock decision until the time of ratification of the Sixteenth Amendment (below).\",\n",
       "  'Legal history of income tax in the United States\\nThe term \"income\" is not defined in the Internal Revenue Code. The closest that Congress comes to defining income is found in the definition of \"gross income\" in Internal Revenue Code section 61, which is largely unchanged from its predecessor, the original Section 22(a) definition of income in the Revenue Act of 1913:',\n",
       "  'Sixteenth Amendment to the United States Constitution\\nNo Tax or Duty shall be laid on Articles exported from any State.',\n",
       "  'Twenty-fourth Amendment to the United States Constitution\\nThe Twenty-fourth Amendment (Amendment XXIV) of the United States Constitution prohibits both Congress and the states from conditioning the right to vote in federal elections on payment of a poll tax or other types of tax. The amendment was proposed by Congress to the states on August 27, 1962, and was ratified by the states on January 23, 1964.',\n",
       "  \"Pollock v. Farmers' Loan & Trust Co.\\nThe Sixteenth Amendment removed the requirement for those income taxes deemed to be direct in substance (such as taxes on income from property) to be apportioned among the states according to population. Thus, the effect of the Pollock decision has indeed been overturned by the Sixteenth Amendment.[11][14][15][16][17]\",\n",
       "  \"Internal Revenue Service\\nThe IRS originated with the Commissioner of Internal Revenue, a federal office created in 1862 to assess the nation's first income tax, which was to raise funds for the American Civil War. The temporary measure provided over a fifth of the Union's war expenses and was allowed to expire a decade later. In 1913, the Sixteenth Amendment to the U.S. Constitution was ratified authorizing Congress to impose a tax on income, and the Bureau of Internal Revenue was established. In 1953, the agency was renamed the Internal Revenue Service and significantly reorganized. The Tax Reform Act of 1986 modernized the IRS and restructured it along a private sector model.\",\n",
       "  \"Sixteenth Amendment to the United States Constitution\\nIt did not take a constitutional amendment to entitle the United States to impose an income tax. Pollock v. Farmers' Loan & Trust Co., 157 U. S. 429, 158 U. S. 601 (1895), only held that a tax on the income derived from real or personal property was so close to a tax on that property that it could not be imposed without apportionment. The Sixteenth Amendment removed that barrier. Indeed, the requirement for apportionment is pretty strictly limited to taxes on real and personal property and capitation taxes.\",\n",
       "  'Taxing and Spending Clause\\nThe resulting case law prohibiting unapportioned taxes on incomes derived from property was later eliminated by the ratification of the Sixteenth Amendment in 1913. The text of the amendment was clear in its aim:'],\n",
       " 'negative_labels': [9.515625,\n",
       "  6.1171875,\n",
       "  13.5859375,\n",
       "  -2.71875,\n",
       "  6.79296875,\n",
       "  4.7578125,\n",
       "  24.46875,\n",
       "  16.3125]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[230340]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positives': {'input_ids': tensor([[     1,    328,    490,  24936,    452,  15968,   9586,    267,    262,\n",
      "            550,      2,  59801,  17841,  59801,    269,   7939,    311,   1066,\n",
      "            335,    373,    269,    411,   6294,    270,    266,  13504,    272,\n",
      "            373,    269,    264,   9586,  77212,    272,    406,    260,  97681,\n",
      "          75544,  59801,    263,   3836,    277,   3910,    265,    342,   1503,\n",
      "            264,    527,    342,    557,    482,    262,   4271,    264,    800,\n",
      "            839,  17444,    260,  59801,  25021,  77212,    263,  13936,    264,\n",
      "          10979,    283,    313,   4461,    264,    552,    315,  25845,    441,\n",
      "            342,    261,    299,    539,   2855,   1969,    267,  82756,    260,\n",
      "            344,    930,    261,  97681,   8466,  13634,   1310,    725,    268,\n",
      "            264,   1727,    283,    266,  13725,    324,    272,  77212,    295,\n",
      "          25845,    315,   9147,    267,   9239,    265,    315,    782,  24772,\n",
      "            260,   5484,  59801,  18335,    275,    386,  38922,    328,   2216,\n",
      "            264,    630,   1023,    265,   2352,    261,    901,    335,    278,\n",
      "            269,    342,    930,    264,   2674,    275,  97681,    261,    313,\n",
      "          17458,    264,  18712,    342,    385,    342,   2855,    260,  77212,\n",
      "          16902,    268,    263,   1603,    315,   2629,    264,   2648,   8584,\n",
      "          97681,    260,    643,    262,   1787,   4271,    261,  77212,  16263,\n",
      "            298,    264,  41939,    262,   2855,    775,    264,  59801,    280,\n",
      "            268,   1838,    265,   2629,    267,    417,    260,    325,    269,\n",
      "            298,    455,    416,    386,    267,   1913,    280,    268,  18963,\n",
      "            488,    264,    391,    272,    262,   2855,    284,    518,  96143,\n",
      "            260,      2,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "              0,      0,      0,      0,      0,      0,      0,      0],\n",
      "        [     1,    361,    597,    284,  12345,  20333,    335,    373,    595,\n",
      "           2674,  13089,      2,   6839,  31255,   4962,  75439,    284,   3740,\n",
      "            267,    737,   1278,   1151,    277,   2521,    265,  31801,   4726,\n",
      "            482,    266,   6544,  26866,    288,    266,   2674,   2027,    968,\n",
      "            267,    485,    920,    844,    482,  11383,    270,    262,    553,\n",
      "            280,    268,   2532,    709,    267,   1413,   1292,    260,  75439,\n",
      "           2325,    267,   1320,    275,   4726,    277,   1278,   1259,    261,\n",
      "           1151,    263,  12132,    307,   2895,   4374,    309,    260,    336,\n",
      "           2358,    284,   3170,    270,   1014,    304,  39320,    264,    903,\n",
      "            456,    261,   1151,    260,   7121,   2390, 111695,  12542,  60879,\n",
      "            272,    401,    262,   2861,  13263,    277,   1341,    261,  75439,\n",
      "            280,    268,   2774,    272,    262,   4741,   5292,    284,  32220,\n",
      "            284,   8725,    260,   2550,   4775,    592,    589,    266,   1278,\n",
      "           2043,   2658,    277,    279,   3388,    261,   4726,   1577,    272,\n",
      "          75439,    263,    342,   7434,  17895,    263,  25540,    281,    363,\n",
      "           1032,  14103,    275,    263,    338,    363,   1032,   1823,    277,\n",
      "           6839,  31255,    260,   2550,   3377,    592,   2550,   4612,    592,\n",
      "            279,   2861,   3265,    262,   3273,    457,  75439,    263,   4726,\n",
      "          13263,    277,   1555,    762,    261,   1151,    260,   2550,   5422,\n",
      "            592,    643,    262,   1061,   2861,    265,    709,    453,    261,\n",
      "          28967,    263,  18779,  42234,  40979,    327,    595,   6839,  31255,\n",
      "           2550,   4921,    592,    401,    265,   3835,  27533,    263,  44226,\n",
      "           1035,   1955,  18779,    260,   2550,   4944,    592,    344,   1370,\n",
      "           1151,    261,    393,    271,   2209,    271,    943,    271,   1371,\n",
      "          25540,  75439,  14094,   4726,    261,    304,  75439,    280,    268,\n",
      "           5970,    284,   8617,    260,   2550,   2554,    592,      2]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}, 'positive_labels': tensor([14.9453, 10.1953]), 'negatives': {'input_ids': tensor([[    1,   328,   490,  ...,     0,     0,     0],\n",
      "        [    1,   328,   490,  ...,     0,     0,     0],\n",
      "        [    1,   328,   490,  ..., 77439,   260,     2],\n",
      "        ...,\n",
      "        [    1,   361,   597,  ...,     0,     0,     0],\n",
      "        [    1,   361,   597,  ...,     0,     0,     0],\n",
      "        [    1,   361,   597,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}, 'negative_labels': tensor([  2.5488,  -1.8682, -12.2344,   7.4727,  -0.7646,  -5.0977,   2.5488,\n",
      "         -0.5522, -14.9453,   1.0195,  -8.8359, -10.8750, -14.9453, -13.5859,\n",
      "        -14.9453, -12.2344])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloaders:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.3906,  8.1562])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"positive_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"positives\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
